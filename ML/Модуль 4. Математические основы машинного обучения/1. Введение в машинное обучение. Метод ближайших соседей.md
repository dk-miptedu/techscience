**Цели недели 1.**
   В результате обучения на этой неделе вы: 

- узнаете, в каких сферах применяется машинное обучение
- узнаете основные понятия машинного обучения: датасет (выборка), объект, признак, таргет, матрица объект-признак, машинное обучение с учителем, таргет, модель, предсказание, функция потерь, параметр, гиперпараметр
- познакомитесь с формальной постановкой задачи машинного обучения с учителем
- научитесь применять метод kNN для решения задач машинного обучения

## 1.1 Введение. Сферы применения машинного обучения

Ссылка на видео: 
[https://disk.yandex.ru/i/nDx6IoLudkxyVQ](https://disk.yandex.ru/i/nDx6IoLudkxyVQ)

## 1.2 Инструкция по настройке локальной машины

![](assets/1.2.Инструкция%20по%20настройке%20локальной%20машины.pdf)

## 1.3 Инструкция по работе с различными онлайн-средами для ноутбуков

![](assets/1.3.Инструкция%20по%20работе%20с%20различными%20онлайн-средами%20для%20ноутбуков.pdf)


## 1.4 Основные понятия машинного обучения

Ссылка на видео: [https://disk.yandex.ru/i/QPIiLcwq0FOgog](https://disk.yandex.ru/i/QPIiLcwq0FOgog)  

## 1.5 Формальная задача машинного обучения с учителем

Ссылка на видео: [https://disk.yandex.ru/i/3gSs-KAKFKWOPw](https://disk.yandex.ru/i/3gSs-KAKFKWOPw)  

## 1.6 Метод k ближайших соседей

Ссылка на видео: [https://disk.yandex.ru/i/YSeatQ0uVqzTSg](https://disk.yandex.ru/i/YSeatQ0uVqzTSg)  

## 1.7 Метрики классификации

Ссылка на видео: [https://disk.yandex.ru/i/tvJKVzfwkWi6iw](https://disk.yandex.ru/i/tvJKVzfwkWi6iw)  

## 1.8 Реализация kNN в Python
Ссылка на видео: [https://disk.yandex.ru/i/zlo9mEuOU55cCw](https://disk.yandex.ru/i/zlo9mEuOU55cCw)  

# **Дополнительные материалы**
## 1.9 Конспект занятия
  
  ![1.9.Конспект (Модуль 4 Неделя 1).pdf](./assets/1.9.Конспект%20(Модуль%204%20Неделя%201).pdf)  
  
# **Проверочные задания**

## 1.10 Задание на программирование 1

[![](https://lms.mipt.ru/theme/image.php/boost/assign/1707999229/icon)1.10 Задание на программирование 1](https://lms.mipt.ru/mod/assign/view.php?id=142633)

код в соответствующих местах для каждой из функций класса `KNearestNeighbor`.

### Вычисление расстояний с двумя циклами

```python
# Внутри метода compute_distances_two_loops
for i in range(num_test):
    for j in range(num_train):
        dists[i, j] = np.sqrt(np.sum(np.square(self.X_train[j] - X[i])))

```

### Вычисление расстояний с одним циклом

```python
# Внутри метода compute_distances_one_loop
for i in range(num_test):
    dists[i, :] = np.sqrt(np.sum(np.square(self.X_train - X[i]), axis=1))
```

### Вычисление расстояний без циклов

```python
# Внутри метода compute_distances_no_loops
# Использование трансляции и свойства (a-b)^2 = a^2 - 2ab + b^2
dists = np.sqrt((np.sum(X**2, axis=1)[:, np.newaxis] + np.sum(self.X_train**2, axis=1)) - 2 * np.dot(X, self.X_train.T))

```

### Предсказание меток

```python
# Внутри метода predict_labels
for i in range(num_test):
    closest_y = []
    # Использование argsort для получения индексов отсортированных элементов
    closest_y_indices = np.argsort(dists[i, :])[:k]
    closest_y = self.y_train[closest_y_indices]
    # Находим самую часто встречающуюся метку среди k ближайших соседей
    y_pred[i] = np.argmax(np.bincount(closest_y))

```

Этот код представляет базовую реализацию алгоритма k-ближайших соседей (KNN) с использованием L2 (евклидова) метрики расстояния. Метод `compute_distances_two_loops` использует два вложенных цикла для вычисления расстояний между обучающими и тестовыми образцами, что является наиболее прямым, но и наименее эффективным способом. Метод `compute_distances_one_loop` использует один цикл для улучшения эффективности, а `compute_distances_no_loops` полностью устраняет явные циклы за счет векторизации, что является самым эффективным подходом с точки зрения вычислительной сложности. Метод `predict_labels` использует полученные расстояния для нахождения k ближайших соседей каждого тестового образца и определения наиболее часто встречающейся метки среди них для предсказания.

