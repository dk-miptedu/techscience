# 4. Случайность. Наивный Байесовский классификатор

**Цели недели 4.**

В результате обучения на этой неделе вы: 

- повторите основные понятия теории вероятностей
- вспомните понятие условной вероятности, дискретных и непрерывных случайных величин
- познакомитесь с центральной предельной теоремой и теоремой Байеса
- узнаете, в каких задачах можно применить наивный Байесовский классификатор

## 4.1 Вероятность. Свойства вероятности

Ссылка на видео: [https://disk.yandex.ru/i/xdJB5vn4sBpMSA](https://disk.yandex.ru/i/xdJB5vn4sBpMSA)  

## 4.2 Условная вероятность. Теорема Байеса

Ссылка на видео: [https://disk.yandex.ru/i/4HH74gTo3NuvJw](https://disk.yandex.ru/i/4HH74gTo3NuvJw)  

## 4.3 Наивный Байесовский классификатор]

Ссылка на видео: [https://disk.yandex.ru/i/LgDkiR6fkwywRQ](https://disk.yandex.ru/i/LgDkiR6fkwywRQ)  

## 4.4 Реализация наивного байесовского классификатора

Ссылка на видео: [https://disk.yandex.ru/i/4vXfh4Uf76XIZw](https://disk.yandex.ru/i/4vXfh4Uf76XIZw)  

## 4.5 Эмпирические функции распределения


Ссылка на видео: [https://disk.yandex.ru/i/XGFIe-HHN-E48A](https://disk.yandex.ru/i/XGFIe-HHN-E48A)  

# **Дополнительные материалы**

## 4.6 Вероятность и статистика

Конспект занятия Файл](https://lms.mipt.ru/mod/resource/view.php?id=142622)
![4.6.Список учебников по теории вероятностей](./assets/4.6.Список%20учебников%20по%20теории%20вероятностей.pdf)

## 4.7 Конспект занятия

![4.7.Конспект Модуль 4 Неделя 4](./assets/4.7.Конспект%20Модуль%204%20Неделя%204.pdf)

# **Проверочные задания**

## 4.8 Задание на программирование 4

** 1. Распределение Лапласа**

Denote the Laplace distribution $\mathcal{L}(\mu, b)$ PDF, where $\mu$ stand for location (loc), and $b$ stands for scale:

$$
f(x|\mu, b) = \frac{1}{2b}\exp(-\frac{|x - \mu|}{b})
$$

Let's implement the `LaplaceDistribution` class. (Of course in practice one could always use something like `scipy.stats.laplace`).

Please note, that making computations with log probabilities is more stable.

#### Description [from Wikipedia](https://en.wikipedia.org/wiki/Laplace_distribution#Statistical_inference):

Given $n$ independent and identically distributed samples $x_1, x_2, ..., x_n$, the maximum likelihood (MLE) estimator of $\mu$ is the sample median:

$$
\hat{\mu} = \mathrm{median}(x).
$$

The MLE estimator $b$ is the mean absolute deviation from the median

$$
\hat{b} = \frac{1}{n} \sum_{i = 1}^{n} |x_i - \hat{\mu}|.
$$


revealing a link between the Laplace distribution and least absolute deviations.

**НЕ ИСПОЛЬЗОВАТЬ кореркцию для малых выборок:**
A correction for small samples can be applied as follows:

$\hat{b}^* = \hat{b} \cdot n/(n-2)$

```python
import numpy as np

class LaplaceDistribution:    
    @staticmethod
    def mean_abs_deviation_from_median(x: np.ndarray):
        '''
        Args:
        - x: A numpy array of shape (n_objects, n_features) containing the data
          consisting of num_train samples each of dimension D.
        '''
        ####
        # Do not change the class outside of this block
        # Your code here
        ####
        median = np.median(x, axis=0)
        mad = np.mean(np.abs(x - median), axis=0)
        return mad
```

```python
def __init__(self, features):

'''

Args:

feature: A numpy array of shape (n_objects, n_features). Every column represents all available values for the selected feature.

'''

####

# Do not change the class outside of this block

self.loc = np.median(features, axis=0)

self.scale = self.mean_abs_deviation_from_median(features) #* len(features) / (len(features) - 2)

####
```

```python
    def logpdf(self, values):
        '''
        Returns logarithm of probability density at every input value.
        Args:
            values: A numpy array of shape (n_objects, n_features). Every column represents all available values for the selected feature.
        '''
        ####
        # Do not change the class outside of this block
        b = self.scale
        mu = self.loc
        log_pdf = - np.log(2 * b) - np.abs(values - mu) / b
        return log_pdf
        ####
 
```

```python
    def pdf(self, values):
        '''
        Returns probability density at every input value.
        Args:
            values: A numpy array of shape (n_objects, n_features). Every column represents all available values for the selected feature.
        '''
        return np.exp(self.logpdf(value))

```

Дедлайн **11.03.2024 (23:59 MSK)**

Обращаем ваше внимание, что оценки заданий из Яндекс.Контеста будут перенесены в LMS после дедлайна.